{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: OpenStreetMap data for Melbourne, Australia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data for project\n",
    "Melbourne, Australia metropolitan area (Node: 21579127) downloaded from:\n",
    " - https://mapzen.com/data/metro-extracts/metro/melbourne_australia/\n",
    " - https://www.openstreetmap.org/node/21579127\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloaded .osm xml file for Melbourne, Australia.\n",
    "\n",
    "Can see the filesize by entering in terminal:\n",
    "\tls -l file_name.osm\n",
    "\n",
    "This returned a value of 855125721 Bytes (or 855 MB)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Created a compressed 'sample' of the dataset using the script provided - sample dataset called 'sample_melb_dataset.osm'.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import xml.etree.cElementTree as ET\n",
    "from collections import defaultdict\n",
    "\n",
    "MELB_DATASET = 'sample_melb_dataset.osm' # replace with full dataset file eventually!!\n",
    "tree = ET.iterparse(MELB_DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'node': 38238, 'nd': 45111, 'member': 1661, 'tag': 22560, 'relation': 45, 'way': 5269, 'osm': 1}\n"
     ]
    }
   ],
   "source": [
    "def count_tags(melb_tree):\n",
    "    tags = {}\n",
    "    for event, elem in melb_tree:\n",
    "        if elem.tag not in tags:\n",
    "            tags[elem.tag] = 1\n",
    "        else:\n",
    "            tags[elem.tag] += 1  \n",
    "    return tags \n",
    "\n",
    "melb_tags = count_tags(tree)\n",
    "print melb_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of tags (and count) in 'melbourne_australia.osm' file:\n",
    "* 'node': 3823741\n",
    "* 'nd': 4494943\n",
    "* 'bounds': 1\n",
    "* 'member': 101777\n",
    "* 'tag': 2230709\n",
    "* 'relation': 4546\n",
    "* 'way': 526873\n",
    "* 'osm': 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Find the user id ('uid') attribute values for the \"node\", \"way\", and \"relation\" tags. Use later to count the number of unique users.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import xml.etree.cElementTree as ET\n",
    "from collections import defaultdict\n",
    "\n",
    "MELB_DATASET = 'sample_melb_dataset.osm' # replace with full dataset file eventually!!\n",
    "tree = ET.iterparse(MELB_DATASET)\n",
    "\n",
    "def find_users(melb_tree):\n",
    "    users = set()\n",
    "    for event, elem in melb_tree:\n",
    "        \n",
    "        if elem.tag == \"node\" or elem.tag == \"way\" or elem.tag == \"relation\":\n",
    "            user = elem.attrib[\"uid\"]\n",
    "            if user not in users:\n",
    "                users.add(user)\n",
    "                \n",
    "    return users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique contributers is: 2499\n"
     ]
    }
   ],
   "source": [
    "users = find_users(tree)\n",
    "print \"Number of unique contributers is: \" + str(len(users))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up some helper functions to extract specific data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# True if is the street name attribute\n",
    "def is_street_name(elem):\n",
    "    return (elem.tag == \"tag\") and (elem.attrib['k'] == \"addr:street\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# True if is the speed limit attribute\n",
    "def is_speed_limit(elem):\n",
    "    return (elem.tag == \"tag\") and (elem.attrib['k'] == \"maxspeed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# True if is the postcode attribute\n",
    "def is_postcode(elem):\n",
    "    return (elem.tag == \"tag\") and (elem.attrib['k'] == \"addr:postcode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# True if is the city name attribute\n",
    "def is_city_name(elem):\n",
    "    return (elem.tag == \"tag\") and (elem.attrib['k'] == \"addr:city\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# True if is the road surface attribute\n",
    "def is_road_surface_type(elem):\n",
    "    return (elem.tag == \"tag\") and (elem.attrib['k'] == \"surface\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# True if is the amenity attribute\n",
    "def is_amenity_type(elem):\n",
    "    return (elem.tag == \"tag\") and (elem.attrib['k'] == \"amenity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audit #1: Cleaning the street 'types'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xml.etree.cElementTree as ET\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import pprint\n",
    "\n",
    "MELB_DATASET = 'sample_melb_data.osm' # replace with full dataset file eventually!!\n",
    "\n",
    "# reg expression searches the end of the string ('$') for a whitespace ('\\b'), any number of non-whitespace\n",
    "# characters ('\\S+'), and 0 or more fullstops ('\\.?')\n",
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "\n",
    "expected = [\"Street\", \"Road\", \"Streets\", \"Street)\", \"Avenue\", \"Close\", \"Court\", \"Ridge\", \"Promenade\", \"Melbourne\", \"Airport\", \"Eyrie\", \"Hub\", \"Loop\", \"Swallow\", \"Myers\", \"Wridgeway\", \"Gateway\", \"Mall\", \"Esplanade\", \"Quay\", \"Freeway\", \"Gardens\", \"Pier\", \"Lane\", \"Strand\", \"Circuit\", \"Reserve\", \"Broadway\", \"Square\", \"Boulevard\", \"Terrace\", \"Highway\", \"Mews\", \"Way\", \"Hill\", \"Grove\", \"Drive\", \"Place\", \"Parade\", \"Crescent\", \"Walk\", \"Strip\", \"North\", \"South\", \"East\", \"West\"]\n",
    "\n",
    "def is_street_name(elem):\n",
    "    return (elem.attrib['k'] == \"addr:street\")\n",
    "\n",
    "def audit_street_type(street_types, street_name):\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type not in expected:\n",
    "            street_types[street_type].add(street_name)\n",
    "\n",
    "\n",
    "def street_type(osmfile):\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    street_types = defaultdict(set)\n",
    "    for event, element in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "        if element.tag == \"way\":\n",
    "            for tag in element.iter(\"tag\"):\n",
    "                if is_street_name(tag):\n",
    "                    # picks out street. Now split into street name and isolate last word!\n",
    "                    # then add to the set\n",
    "                    audit_street_type(street_types, tag.attrib['v'])\n",
    "    osm_file.close()        \n",
    "    return street_types\n",
    "\n",
    "# define 'mapping' dict to correct street types\n",
    "street_type_map = {\n",
    "    \"Rd\": \"Road\",\n",
    "    \"rd\": \"Road\",\n",
    "    \"St\": \"Street\",\n",
    "    \"road\": \"Road\",\n",
    "    \"street\": \"Street\",\n",
    "    \"crescent\": \"Crescent\",\n",
    "    \"avenue\": \"Avenue\",\n",
    "    \"Rigbystreet\": \"Rigby Street\",\n",
    "    \"Roadl\": \"Road\",\n",
    "    \"Stree\": \"Street\",\n",
    "    \"Ave\": \"Avenue\",\n",
    "    \"Cresecnt\": \"Crescent\",\n",
    "    \"Higway\": \"Highway\"\n",
    "}\n",
    "\n",
    "def update_street_type(name, mapping):\n",
    "    m = street_type_re.search(name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type in mapping:\n",
    "            new_name = name[:-len(street_type)] + mapping[street_type]  \n",
    "    \n",
    "            return new_name\n",
    "        else:\n",
    "            return name\n",
    "\n",
    "def test():\n",
    "    st_types = street_type(MELB_DATASET)\n",
    "    pprint.pprint(dict(st_types))\n",
    "\n",
    "    for st_type, ways in st_types.iteritems():\n",
    "        for name in ways:\n",
    "            better_name = update_street_type(name, street_type_map)\n",
    "            print name, \"=>\", better_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'3220': set(['3220']),\n",
      " 'Ave': set(['Wondoora Ave']),\n",
      " 'Cresecnt': set(['Camellia Cresecnt']),\n",
      " 'Esperence': set(['The Esperence']),\n",
      " 'Higway': set(['Maroondah Higway']),\n",
      " 'Preston': set(['2B Stott St Preston']),\n",
      " 'Rd': set(['Roberts Rd']),\n",
      " 'Rigbystreet': set(['Rigbystreet']),\n",
      " 'Road1': set(['Dynon Road1']),\n",
      " 'Roads': set(['Sydney and Brunswick Roads']),\n",
      " 'St': set(['Adelaide St',\n",
      "            'Bay St',\n",
      "            'Federal St',\n",
      "            'Lygon St',\n",
      "            'Pelham St',\n",
      "            'Susan St',\n",
      "            'Victoria St',\n",
      "            'kennedy St']),\n",
      " 'Stree': set(['Graham Stree']),\n",
      " 'avenue': set(['Teague avenue']),\n",
      " 'crescent': set(['Amayla crescent']),\n",
      " 'rd': set(['Baxter-Tooradin rd', 'Frankston-Flinders rd']),\n",
      " 'road': set(['Arthurs seat scenic road',\n",
      "              'Baxter-Tooradin road',\n",
      "              'Dammans road',\n",
      "              'Wheatherall road']),\n",
      " 'street': set(['Beach street',\n",
      "                'Church street',\n",
      "                'Kavanagh street',\n",
      "                'Separation street'])}\n",
      "Camellia Cresecnt => Camellia Crescent\n",
      "2B Stott St Preston => 2B Stott St Preston\n",
      "3220 => 3220\n",
      "Graham Stree => Graham Street\n",
      "Federal St => Federal Street\n",
      "kennedy St => kennedy Street\n",
      "Adelaide St => Adelaide Street\n",
      "Bay St => Bay Street\n",
      "Lygon St => Lygon Street\n",
      "Victoria St => Victoria Street\n",
      "Pelham St => Pelham Street\n",
      "Susan St => Susan Street\n",
      "Frankston-Flinders rd => Frankston-Flinders Road\n",
      "Baxter-Tooradin rd => Baxter-Tooradin Road\n",
      "The Esperence => The Esperence\n",
      "Separation street => Separation Street\n",
      "Kavanagh street => Kavanagh Street\n",
      "Beach street => Beach Street\n",
      "Church street => Church Street\n",
      "Amayla crescent => Amayla Crescent\n",
      "Roberts Rd => Roberts Road\n",
      "Sydney and Brunswick Roads => Sydney and Brunswick Roads\n",
      "Wondoora Ave => Wondoora Avenue\n",
      "Dynon Road1 => Dynon Road1\n",
      "Teague avenue => Teague Avenue\n",
      "Rigbystreet => Rigby Street\n",
      "Dammans road => Dammans Road\n",
      "Arthurs seat scenic road => Arthurs seat scenic Road\n",
      "Wheatherall road => Wheatherall Road\n",
      "Baxter-Tooradin road => Baxter-Tooradin Road\n",
      "Maroondah Higway => Maroondah Highway\n"
     ]
    }
   ],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printed out all the street names for which the 'types' weren't in the defined 'expected' list.\n",
    "\n",
    "Updated the list accordingly with acceptable values, including \"North\"/\"South\"/\"East\"/\"West\". This was performed iteratively to acheive the correct 'expected' list.\n",
    "\n",
    "Will 'clean' others. Most are just either abbreviations (\"St\", \"Ave\", etc) or lowercase (\"street\", \"road\").\n",
    "Some are typos (e.g. \"Stree\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now need to clean the street_type data that looks incorrect.\n",
    "\n",
    "Made some judgement calls based on the context of what the street_type function returned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now need to update the incorrect street name data! <-- STILL NEED TO DO THIS!!!!!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audit #2: Let's check out what kinds of 'amenities' are in Melbourne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xml.etree.cElementTree as ET\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import pprint\n",
    "\n",
    "MELB_DATASET = 'sample_melb_dataset.osm' # replace with full dataset file eventually!!\n",
    "\n",
    "# True if is the amenity attribute\n",
    "def is_amenity_type(elem):\n",
    "    return (elem.tag == \"tag\") and (elem.attrib['k'] == \"amenity\")\n",
    "\n",
    "# make a 'set' of all the listed amenties\n",
    "def list_of_amenities(osmfile):\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    amenities = set()\n",
    "    for event, element in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "        if element.tag == \"node\":\n",
    "            for elem in element.iter(\"tag\"):\n",
    "                if is_amenity_type(elem):\n",
    "                    amenities.add(elem.attrib['v'])\n",
    "    osm_file.close()\n",
    "    return amenities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taxi\n",
      "dojo\n",
      "picnic_table\n",
      "office\n",
      "social_facility\n",
      "taxi_point\n",
      "clinic\n",
      "embassy\n",
      "post_office\n",
      "bureau_de_change\n",
      "toilets\n",
      "bicycle_repair_station\n",
      "police\n",
      "courthouse\n",
      "community_centre\n",
      "internet_cafe\n",
      "pharmacy\n",
      "kindergarten\n",
      "fuel\n",
      "art_school\n",
      "leisure\n",
      "waste_basket\n",
      "bank\n",
      "fish farm\n",
      "place_of_worship\n",
      "school\n",
      "bar\n",
      "parking_entrance\n",
      "university\n",
      "physiotherapy\n",
      "brothel\n",
      "bowling\n",
      "water_point\n",
      "waste_disposal\n",
      "physiotherapist\n",
      "restaurant; cafe\n",
      "car_sharing\n",
      "fire_station\n",
      "newsagent\n",
      "library\n",
      "stripclub\n",
      "college\n",
      "parking\n",
      "optometrist\n",
      "surgery\n",
      "yes\n",
      "ambulance_station\n",
      "charging_station\n",
      "beauty\n",
      "food_court\n",
      "clock\n",
      "veterinary\n",
      "PO boxes\n",
      "convenience\n",
      "weighbridge\n",
      "fountain\n",
      "exercise\n",
      "fast_food\n",
      "post_box\n",
      "pub\n",
      "studio\n",
      "biergarten\n",
      "video_store\n",
      "bicycle_rental\n",
      "townhall\n",
      "training\n",
      "motorcycle_parking\n",
      "restaurant\n",
      "trash_can\n",
      "ferry_terminal\n",
      "atm\n",
      "nightclub\n",
      "bus_station\n",
      "massage\n",
      "toy_library\n",
      "driving_school\n",
      "audiologist\n",
      "recycling\n",
      "nursing_home\n",
      "marker\n",
      "bench\n",
      "engineer\n",
      "boat_rental\n",
      "skatepark\n",
      "compressed_air\n",
      "hospital\n",
      "vehicle_inspection\n",
      "jetty\n",
      "sports\n",
      "car_rental\n",
      "bicycle_parking\n",
      "telephone_exchange\n",
      "drinking_water\n",
      "club\n",
      "gym\n",
      "public_hall\n",
      "dentist\n",
      "doctors\n",
      "shower\n",
      "parking_space\n",
      "bbq\n",
      "winery\n",
      "rsl\n",
      "marketplace\n",
      "casino\n",
      "public_building\n",
      "cinema\n",
      "bikesharing_station\n",
      "car_wash\n",
      "telephone\n",
      "hunting_stand\n",
      "childcare\n",
      "health_centre\n",
      "spa\n",
      "pathology\n",
      "cafe\n",
      "bus hire\n",
      "sanitary_dump_station\n",
      "waste_transfer_station\n",
      "coworking_space\n",
      "child_care\n",
      "arts_centre\n",
      "philatelic\n",
      "bandstand\n",
      "assisted_living\n",
      "printer\n",
      "theatre\n",
      "shelter\n",
      "community_hall\n",
      "sauna\n",
      "parking_meter\n",
      "statue\n",
      "ice_cream\n",
      "karaoke_box\n",
      "dog_wash\n",
      "proposed\n",
      "wifi\n",
      "public_bookcase\n",
      "swimming_pool\n",
      "support service\n",
      "vending_machine\n",
      "allied_health\n"
     ]
    }
   ],
   "source": [
    "amentiy_list = list_of_amenities(MELB_DATASET)\n",
    "for i in amentiy_list:\n",
    "    print i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having printed the list of amenities, the data looks pretty clean. The only thing is their is an amenity called \"yes\", which seems like an incorrect input. Will find the entries containing this as an amentiy and remove/update them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set([])\n"
     ]
    }
   ],
   "source": [
    "# this only works on the full dataset, not the sample file!\n",
    "def find_yes(osmfile):\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    amenity_is_yes = set()\n",
    "    for event, element in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "        if element.tag == \"node\":\n",
    "            for tag in element.iter(\"tag\"):\n",
    "                if is_amenity_type(tag) and (tag.attrib['v'] == \"yes\"):\n",
    "                    amenity_is_yes.add(element.attrib['id'])\n",
    "    osm_file.close()\n",
    "    return amenity_is_yes\n",
    "\n",
    "print find_yes(MELB_DATASET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like it's only one entry (a \"node\" with \"id=2674416306\") that has \"yes\" as an \"amenity\" attribute.\n",
    "\n",
    "The entry has an amenity for \"name = barbeque\". As there are other amenity entries as \"bbq\", will update this one to that also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_bbq_entry(entry):\n",
    "    entry.attrib['v'] = \"bbq\"\n",
    "\n",
    "# now re-run the code to find the culprit entry and update it\n",
    "def find_yes_and_update(filename):\n",
    "    #open_osm = open(filename, \"r+\")\n",
    "    for event, element in ET.iterparse(filename):\n",
    "        if element.tag == \"node\":\n",
    "            for tag in element.iter(\"tag\"):\n",
    "                if is_amenity_type(tag) and (tag.attrib['v'] == \"yes\"):\n",
    "                    update_bbq_entry(tag)\n",
    "    #open_osm.close()\n",
    "\n",
    "find_yes_and_update(MELB_DATASET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audit #3: Check postcodes for validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VIC 3931 => 3931\n",
      "Vic 3182 => 3182\n",
      "31195 => 31195\n",
      "2197 => 3197\n",
      "38058 => 3805\n",
      "4220 => None\n",
      "VIC 3805 => 3805\n",
      "VIC 3000 => 3000\n",
      "VIC 3796 => 3796\n",
      "3040‎ => 3040‎\n",
      "Victoria => 3168\n",
      "Vic 3789 => 3789\n",
      "VIC 3166 => 3166\n",
      "3206Unset => 3206\n",
      "Melbourne => 3000\n",
      "VIC 3770 => 3770\n",
      "3006;3130 => 3006\n",
      "Centre Dandenong Road => 3192\n",
      "Yarra Street => 3220\n",
      "Carlton => 3053\n",
      "805 => 3805\n",
      "2004 => 3205\n",
      "Albert Street => 3205\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.cElementTree as ET\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import pprint\n",
    "\n",
    "MELB_DATASET = 'sample_melb_dataset.osm' # replace with full dataset file eventually!!\n",
    "# re to check if is 4-digit postcode starting with \"3\"\n",
    "postcode_re = re.compile(r'^3\\d{,3}$', re.IGNORECASE)\n",
    "\n",
    "# True if is the postcode attribute\n",
    "def is_postcode(elem):\n",
    "    return (elem.tag == \"tag\") and (elem.attrib['k'] == \"addr:postcode\")\n",
    "\n",
    "def audit_postcode_set(problem_postcodes_set, postcode):\n",
    "    m = postcode_re.search(postcode)\n",
    "    if not m:\n",
    "        problem_postcodes_set.add(postcode)\n",
    "\n",
    "\n",
    "def audit_postcode(osmfile):\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    problem_postcodes = set()\n",
    "    for event, element in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "        if element.tag == \"way\":\n",
    "            for tag in element.iter(\"tag\"):\n",
    "                if is_postcode(tag):\n",
    "                    # picks out street. Now split into street name and isolate last word!\n",
    "                    # then add to the set\n",
    "                    audit_postcode_set(problem_postcodes, tag.attrib['v'])\n",
    "        elif element.tag == \"node\":\n",
    "            for tag in element.iter(\"tag\"):\n",
    "                if is_postcode(tag):\n",
    "                    # picks out street. Now split into street name and isolate last word!\n",
    "                    # then add to the set\n",
    "                    audit_postcode_set(problem_postcodes, tag.attrib['v'])\n",
    "                    \n",
    "    osm_file.close()        \n",
    "    return problem_postcodes\n",
    "\n",
    "#print audit_postcode(MELB_DATASET)\n",
    "c\n",
    "#------------------------------------------------\n",
    "\n",
    "postcode_mapping = {\n",
    "    \"Carlton\": \"3053\",\n",
    "    \"Yarra Street\": \"3220\",\n",
    "    \"Centre Dandenong Road\": \"3192\",\n",
    "    \"Albert Street\": \"3205\",\n",
    "    \"Melbourne\": \"3000\",\n",
    "    \"Victoria\": \"3168\",\n",
    "    \"2004\": \"3205\",\n",
    "    \"31195\": \"3195\",\n",
    "    \"385\": \"3805\",\n",
    "    \"805\": \"3805\",\n",
    "    \"4220\": None,\n",
    "    \"2197\": \"3197\",\n",
    "    \"38058\": \"3805\",\n",
    "    \"3040\\\\u200e\": \"3040\",\n",
    "    \"3206Unset\": \"3206\",\n",
    "    \"3006;3130\": \"3006\"\n",
    "}\n",
    "\n",
    "def update_postcodes(postcode, mapping):\n",
    "    if postcode in mapping:\n",
    "        new_postcode = mapping[postcode]\n",
    "        return new_postcode\n",
    "    elif (postcode[:3] == \"VIC\") or (postcode[:3] == \"Vic\"):\n",
    "        return postcode[4:]\n",
    "    else:\n",
    "        return postcode\n",
    "\n",
    "def test():\n",
    "    pcodes = audit_postcode(MELB_DATASET)\n",
    "    #pprint.pprint(dict(pcodes))\n",
    "\n",
    "    for pcode in pcodes:\n",
    "        new_pcode = update_postcodes(pcode, postcode_mapping)\n",
    "        print pcode, \"=>\", new_pcode\n",
    "\n",
    "test()\n",
    "            \n",
    "#postcodes = list_of_postcodes(MELB_DATASET)\n",
    "#for postcode in postcodes:\n",
    "#    print postcode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the only errors in \"postcode\" entries are where there contains some text (e.g. VIC 3030), or contains only text (e.g. \"Carlton\").\n",
    "\n",
    "Running the script to check for problem postcodes returned the set:\n",
    "\n",
    "    set(['VIC 3000', 'Yarra Street', 'Victoria', 'Vic 3182', 'Carlton', '2004', '2197', 'VIC 3770', '4220'])\n",
    "\n",
    "This is a relatively small amount of errors to be corrected.\n",
    "\n",
    "Will make two scripts, one to remove text from the first error type, and one to map the text-only error to its proper postcode (e.g. Carlton should be 3053).\n",
    "\n",
    "**After creating the SQL db, it was observed that the 'nodes_tags' table also contains entries for postcodes**\n",
    "\n",
    "The 'audit_postcode' function was ammended to include this subset of the data, and the 'postcode_mapping' dict updated to include the problematic entries found.\n",
    "\n",
    "The csv-writing and sql-db-creating scripts were then compiled again to update the 'toms_osm.db' database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xml.etree.cElementTree as ET\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import pprint\n",
    "\n",
    "MELB_DATASET = 'sample_melb_dataset.osm' # replace with full dataset file eventually!!\n",
    "\n",
    "# True if is the postcode attribute\n",
    "def is_postcode(elem):\n",
    "    return (elem.tag == \"tag\") and (elem.attrib['k'] == \"addr:postcode\")\n",
    "\n",
    "def find_postcodes(osmfile):\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    for event, element in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "        if element.tag == \"way\":\n",
    "            for tag in element.iter(\"tag\"):\n",
    "                if is_postcode(tag):\n",
    "                    if tag.attrib['v'] == \"Victoria\":\n",
    "                        # picks out street. Now split into street name and isolate last word!\n",
    "                        # then add to the set\n",
    "                        print element.attrib[\"id\"]\n",
    "    osm_file.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Searched for the matching entries that had postcodes that didn't start with \"3\". Just wanted to see if they were entry errors, or something else.\n",
    "\n",
    "Returned way-tag id's: 51253585, 266740971, 446614243.\n",
    "\n",
    "* For way.id=51253585 (postcode=2004), the entry is for a location in South Melbourne. This should have a postcode of \"3205\".\n",
    "* For way.id=266740971 (postcode=4220), the entry does not have a defined location. Will remove the postcode attribute.\n",
    "* For way.id=446614243 (postcode=2197), the entry is for a location in Carrum. This should have a postcode of \"3197\".\n",
    "\n",
    "Searching for \"Yarra Street\" (way.id=266729151) revealed that the \"addr:street\" and \"addr:postcode\" attributes have each others values! Postcode should be \"3220\".\n",
    "\n",
    "Searching for \"Victoria (way.id=48333668) had an entry based in Clayton. Therefore, the postcode should be updated to \"3168\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing the xml data into csv files:\n",
    "See the other notebook 'osm-csv-writer.pynb' for the full cleaning/writing function (adapted from Lesson 13 'Case study', with cleaning modifications changed to perform those identified above)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## How to create a SQLite database manually in the command line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# move to desired working directory\n",
    "# create a new database file called 'database_name.db'\n",
    "$ sqlite3 database_name.db\n",
    "# with sqlite3 now running, can create a new table with\n",
    "...sqlite> CREATE TABLE table_name[optional parameters]\n",
    "# the new table should show up now when '.tables' is called\n",
    "...sqlite> .tables\n",
    "...sqlite> table_name\n",
    "# check the 'schema' of the new table with\n",
    "...sqlite> .schema table_name\n",
    "# to load a .csv file can use the following\n",
    "...sqlite> .mode csv\n",
    "...sqlite> .import file_name.csv new_table_name\n",
    "# the above creates a new table from the .csv file, skipping the first 'headers' line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to create a SQLite database programmatically in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import the required modules\n",
    "import sqlite3\n",
    "import csv\n",
    "from pprint import pprint\n",
    "\n",
    "# connect to the database (if it doesn't exist it will be created)\n",
    "sqlite_file = 'toms_osm.db' # name of the sql database file\n",
    "conn = sqlite3.connect(sqlite_file) # connect to db file\n",
    "\n",
    "# create cursor object\n",
    "cur = conn.cursor()\n",
    "\n",
    "# creating tables\n",
    "# if you are replacing a table, \"DROP\" the previous version first (e.g. a table 'nodes_tags')\n",
    "cur.execute('''DROP TABLE IF EXISTS nodes''')\n",
    "cur.execute('''DROP TABLE IF EXISTS nodes_tags''')\n",
    "cur.execute('''DROP TABLE IF EXISTS ways''')\n",
    "cur.execute('''DROP TABLE IF EXISTS ways_tags''')\n",
    "cur.execute('''DROP TABLE IF EXISTS ways_nodes''')\n",
    "\n",
    "conn.commit() # commits changes to database\n",
    "\n",
    "# to create the table, specifiy coloumn names and data types\n",
    "# create the nodes table\n",
    "cur.execute ('''\n",
    "        CREATE TABLE nodes(id INTEGER PRIMARY KEY NOT NULL, lat REAL, lon REAL, user TEXT, uid INTEGER, version INTEGER, changeset INTEGER, timestamp TEXT)\n",
    "''')\n",
    "# create the nodes_tags table\n",
    "cur.execute ('''\n",
    "        CREATE TABLE nodes_tags(id INTEGER, key TEXT, value TEXT, type TEXT, FOREIGN KEY (id) REFERENCES nodes(id))\n",
    "''')\n",
    "# create the ways table\n",
    "cur.execute ('''\n",
    "        CREATE TABLE ways(id INTEGER PRIMARY KEY NOT NULL, user TEXT, uid INTEGER, version INTEGER, changeset INTEGER, timestamp TEXT)\n",
    "''')\n",
    "# create the ways_tags table\n",
    "cur.execute ('''\n",
    "        CREATE TABLE ways_tags(id INTEGER NOT NULL, key TEXT NOT NULL, value TEXT NOT NULL, type TEXT, FOREIGN KEY (id) REFERENCES ways(id))\n",
    "''')\n",
    "\n",
    "# create the ways_nodes table\n",
    "cur.execute ('''\n",
    "        CREATE TABLE ways_nodes(id INTEGER NOT NULL, node_id INTEGER NOT NULL, position INTEGER NOT NULL, FOREIGN KEY (id) REFERENCES ways(id), FOREIGN KEY (node_id) REFERENCES nodes(id))\n",
    "''')\n",
    "\n",
    "# commit the changes\n",
    "conn.commit()\n",
    "\n",
    "#------------------------------------------\n",
    "\n",
    "# Time to read/load in the data.\n",
    "\n",
    "# Read the csv file as a dictionary, format the data as a list of tuples\n",
    "# note: the .decode(\"utf-8\") converts any non-ASCII characters before importing them\n",
    "\n",
    "# read in the nodes_tags file\n",
    "with open('nodes.csv', 'rb') as nodes:\n",
    "    node_dr = csv.DictReader(nodes) # comma is default delimiter\n",
    "    nodes_db = [(i['id'].decode(\"utf-8\"), i['user'].decode(\"utf-8\"), i['uid'].decode(\"utf-8\"), i['version'].decode(\"utf-8\"), i['changeset'].decode(\"utf-8\"), i['timestamp']) for i in node_dr]\n",
    "    \n",
    "# read in the nodes_tags file\n",
    "with open('nodes_tags.csv', 'rb') as nodes_tags:\n",
    "    node_tag_dr = csv.DictReader(nodes_tags) # comma is default delimiter\n",
    "    nodes_tags_db = [(i['id'].decode(\"utf-8\"), i['key'].decode(\"utf-8\"), i['value'].decode(\"utf-8\"), i['type'].decode(\"utf-8\")) for i in node_tag_dr]\n",
    "    \n",
    "# read in the nodes_tags file\n",
    "with open('ways.csv', 'rb') as ways:\n",
    "    way_dr = csv.DictReader(ways) # comma is default delimiter\n",
    "    ways_db = [(i['id'].decode(\"utf-8\"), i['user'].decode(\"utf-8\"), i['uid'].decode(\"utf-8\"), i['version'].decode(\"utf-8\"), i['changeset'].decode(\"utf-8\"), i['timestamp']) for i in way_dr]\n",
    "    \n",
    "# read in the nodes_tags file\n",
    "with open('ways_tags.csv', 'rb') as ways_tags:\n",
    "    way_tag_dr = csv.DictReader(ways_tags) # comma is default delimiter\n",
    "    ways_tags_db = [(i['id'].decode(\"utf-8\"), i['key'].decode(\"utf-8\"), i['value'].decode(\"utf-8\"), i['type'].decode(\"utf-8\")) for i in way_tag_dr]\n",
    "\n",
    "# read in the nodes_tags file\n",
    "with open('ways_nodes.csv', 'rb') as ways_nodes:\n",
    "    way_node_dr = csv.DictReader(ways_nodes) # comma is default delimiter\n",
    "    ways_nodes_tags_db = [(i['id'].decode(\"utf-8\"), i['node_id'].decode(\"utf-8\"), i['position'].decode(\"utf-8\")) for i in way_node_dr]\n",
    "\n",
    "#------------------------------------------\n",
    "\n",
    "# now insert the formated data into the sql table\n",
    "\n",
    "cur.executemany(\"INSERT INTO nodes(id, user, uid, version, changeset, timestamp) VALUES (?, ?, ?, ?, ?, ?);\", nodes_db)\n",
    "cur.executemany(\"INSERT INTO nodes_tags(id, key, value, type) VALUES (?, ?, ?, ?);\", nodes_tags_db)\n",
    "cur.executemany(\"INSERT INTO ways(id, user, uid, version, changeset, timestamp) VALUES (?, ?, ?, ?, ?, ?);\", ways_db)\n",
    "cur.executemany(\"INSERT INTO ways_tags(id, key, value, type) VALUES (?, ?, ?, ?);\", ways_tags_db)\n",
    "cur.executemany(\"INSERT INTO ways_nodes(id, node_id, position) VALUES (?, ?, ?);\", ways_nodes_tags_db)\n",
    "\n",
    "# commit the changes\n",
    "conn.commit()\n",
    "\n",
    "# can make QUERIES using the following general structure\n",
    "'''\n",
    "# check the import worked correctly\n",
    "cur.execute('SELECT * FROM nodes_tags')\n",
    "all_rows = cur.fetchall()\n",
    "print('1):')\n",
    "pprint(all_rows)\n",
    "'''\n",
    "\n",
    "# close the connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
