{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenStreetMap Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data for project\n",
    "\n",
    "Melbourne, Australia metropolitan area (Node: 21579127) downloaded from:\n",
    "- https://mapzen.com/data/metro-extracts/metro/melbourne_australia/\n",
    "- https://www.openstreetmap.org/node/21579127"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of dataset\n",
    "\n",
    "Downloaded .osm file for Melbourne has a size of 855125721 Bytes (855 MB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Looping through the ElementTree object, I was able to some general stats for no. of nodes, tags, and unique contributers, etc.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of tags (and count) in 'melbourne_australia.osm' file:\n",
    "* 'node': 3823741\n",
    "* 'nd': 4494943\n",
    "* 'bounds': 1\n",
    "* 'member': 101777\n",
    "* 'tag': 2230709\n",
    "* 'relation': 4546\n",
    "* 'way': 526873\n",
    "* 'osm': 1\n",
    "\n",
    "Number of unique contributers is: 2499"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auditing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audit #1: cleaning the street 'types'\n",
    "\n",
    "A function was written using a regex expression to isolate the last word in the 'street name' (assumed to be the street 'type', e.g. 'Road').\n",
    "\n",
    "This was then checked against an 'expected set' of values, with the output values either added to the expected set, or corrected via a 'mapping' dictionary depending on my assesment of their validity.\n",
    "\n",
    "This code was used to write a .py script called 'street_type_cleaner.py' that can be called from the shape_element() function later when writing the data to .csv format.\n",
    "\n",
    "Note: Most errors were with abbreviations (\"St\", \"Ave\", etc) or lowercase (\"street\", \"road\"), although there were some typos (\"Stree\"); these were all converted to capatilized full words (e.g. \"Street\", \"Road\").\n",
    "\n",
    "Also, it should be noted that \"North\"/\"South\"/\"East\"/\"West\" were added to the list of acceptable types, as they often occur at the end of the street string (e.g.\"Balwyn Road South\"). However, others may prefer to change how these cases are handled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*A test function was written to show which entries had been modified, and what their 'corrected' output was.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From the test(), the street types appeared to be cleaned up correctly with this auditing function.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audit #2: looking at the 'amenities' in Melbourne\n",
    "\n",
    "I wanted to see what types of 'amenities' there were listed for various nodes in Melbourne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I started by printing out the full list of amenities. This list was not so big that I couldn't browse the entire thing as is.\n",
    "\n",
    "It looked pretty clean. The only thing was there was an amenity called \"yes\", which seemed like an incorrect input. \n",
    "\n",
    "Next, I tried to find the entry/entries containing this as an amentiy and remove/update them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_yes(osmfile):\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    amenity_is_yes = set()\n",
    "    for event, element in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "        if element.tag == \"node\":\n",
    "            for tag in element.iter(\"tag\"):\n",
    "                if is_amenity_type(tag) and (tag.attrib['v'] == \"yes\"):\n",
    "                    amenity_is_yes.add(element.attrib['id'])\n",
    "    osm_file.close()\n",
    "    return amenity_is_yes\n",
    "\n",
    "print find_yes(MELB_DATASET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seemed to be only one entry (a \"node\" with \"id=2674416306\") that had \"yes\" as an \"amenity\" attribute.\n",
    "\n",
    "This specific entry also had an attribute \"name = barbeque\". As there are other amenity entries as \"bbq\", I chose to update this one to also have \"amenity='bbq'\". This was done in the shape_element() function by finding the amenity with \"yes\" as a value, then applying a simple function saved in the 'amenity_cleaner.py' file that updated the attribute value to \"bbq\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if (tag.attrib[\"k\"] == \"amenity\") and (tag.attrib[\"v\"] == \"yes\"):\n",
    "    new_amentity_value = am.update_amenity_type()\n",
    "    node_tag_dict.update({\"key\": tag.attrib[\"k\"], \"value\": new_amentity_value, \"type\": \"regular\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the rest of the amenity entries appeared ok, no further cleaning was applied."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audit #3: check 'postcode' validity\n",
    "\n",
    "A regex was used to identify problematic postcodes in the dataset. These were defined as 'not starting with 3 and containing four numbers'.\n",
    "\n",
    "A script was written to identify any non-conforming postcodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Initially, only the \"way\" elements were assessed for postcode entries. After creating the SQLite database at a later stage, it was noticed that there were problematic entries for the tags in the \"node\" element also. Therefore, an 'elif element.tag == \"node\":' statement was added, which appeared to resolve the issue after the mapping dictionary was updated with the newly-identified problematic entries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of this function was then used to build a 'mapping' dictionary that could correct any problematic entries.\n",
    "\n",
    "Some searching was required to identify the actual postcodes of some non-conforming entries, or what they should be based on other attributes listed in the relevant tags. For example:\n",
    "Searching for \"Yarra Street\" (way.id=266729151) revealed that the \"addr:street\" and \"addr:postcode\" attributes have each others values! Postcode should be \"3220\".\n",
    "Searching for \"Victoria (way.id=48333668) had an entry based in Clayton. Therefore, the postcode should be updated to \"3168\".\n",
    "\n",
    "A test() function was written as above, before adapting the code for the 'postcode_cleaner.py' script to be called directly from the shape_element function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing the xml data into csv files\n",
    "\n",
    "The code to write csv files from the input xml/osm file was adapted from Lesson 13: Case Study.\n",
    "\n",
    "The cleaning/auditing functions developed above were incorporated into the relevant section of the shape_element() function.\n",
    "\n",
    "See the 'osm_melb_csv_writer.py' file for the full code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the SQLite database with the 'cleaned' data\n",
    "\n",
    "**The newly created .csv files were loaded into various tables of a new database using Python DB-API (adapted from several threads in the Udacity forums)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the schema provided, the tables 'nodes', 'nodes_tags', 'ways', 'ways_tags', and 'ways_nodes' were created and populated with the relavent csv files.\n",
    "\n",
    "See 'sql_db_generator.py' file for code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying the new SQLite database\n",
    "\n",
    "The querying was performed using the Python DB-API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check street names for cleanliness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A basic test to see if the 'clean' street names had been loaded into the database was performed by searching for both the problematic version (identified during the data auditing step), and a 'cleaned' name.\n",
    "\n",
    "*For example:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SELECT tags.value FROM (SELECT * FROM nodes_tags) tags WHERE tags.key='street' \n",
    "    AND tags.value='Camellia Cresecnt' GROUP BY tags.value;\n",
    "\n",
    "SELECT tags.value FROM (SELECT * FROM nodes_tags) tags WHERE tags.key='street' \n",
    "    AND tags.value='Camellia Crescent' GROUP BY tags.value;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dirty name was not found, where the clean one was. This was repeated for several entries to confirm the presence of the cleaned data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** When this check was run on the first version of the database, several erroneous entries were found (it is assumed that bad entries will have low 'counts', so only those with count < 5 need to be examined)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Similar checks were run for both the 'postcode' and the 'amenity' fields (code note shown). These tests indicate that the database data had been cleaned successfully.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other statistics about the Melbourne dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3823741,)]\n"
     ]
    }
   ],
   "source": [
    "SELECT COUNT(*) FROM nodes;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3823741"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This matches the number calculated from the original xml file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of unique users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2493,)]\n"
     ]
    }
   ],
   "source": [
    "SELECT COUNT(DISTINCT(tag.uid)) FROM (SELECT uid FROM nodes UNION ALL SELECT uid FROM ways) tag;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2493"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is slightly lower than the value calculated from the raw xml (2499). This may indicated that some entries have been removed from the dataset during our cleaning/file conversion processing, e.g. those with problematic characters. However the difference is relatively minor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 10 types of \"surface\" for \"ways\"\n",
    "i.e. tag.attrib['surface']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'asphalt', 29084),\n",
      " (u'paved', 8918),\n",
      " (u'concrete', 7152),\n",
      " (u'unpaved', 4423),\n",
      " (u'gravel', 1989),\n",
      " (u'dirt', 1134),\n",
      " (u'grass', 817),\n",
      " (u'cobblestone', 375),\n",
      " (u'ground', 249),\n",
      " (u'wood', 167)]\n"
     ]
    }
   ],
   "source": [
    "SELECT value, COUNT(*) as count FROM ways_tags WHERE key='surface' GROUP BY value ORDER BY count DESC LIMIT 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "asphalt (29084)  \n",
    "paved (8918)  \n",
    "concrete (7152)  \n",
    "unpaved (4423)  \n",
    "gravel (1989)  \n",
    "dirt (1134)  \n",
    "grass (817)  \n",
    "cobblestone (375)  \n",
    "ground (249)  \n",
    "wood (167)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No. of churches and no. of post offices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'place_of_worship', 494), (u'post_office', 266)]\n"
     ]
    }
   ],
   "source": [
    "SELECT value, COUNT(*) as count FROM nodes_tags WHERE key='amenity' \n",
    "    AND (value='place_of_worship' or value='post_office') GROUP BY value;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 494 churches and 266 post offices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the top 5 \"barriers\" in Melbourne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'fence', 26759),\n",
      " (u'wall', 266),\n",
      " (u'hedge', 228),\n",
      " (u'retaining_wall', 152),\n",
      " (u'wire_fence', 133)]\n"
     ]
    }
   ],
   "source": [
    "SELECT value, COUNT(*) as count FROM ways_tags WHERE key='barrier' GROUP BY value ORDER BY count DESC LIMIT 5;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fence (26759)  \n",
    "wall (266)  \n",
    "hedge (228)  \n",
    "retaining_wall (152)  \n",
    "wire_fence (133)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like a lot of hedges!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Ideas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing data fields\n",
    "\n",
    "It seems to me that the biggest problem with the dataset is missing attributes. Specifically, values for 'amenity' appear to be entered infrequently. For example, there are 494 nodes tagged as 'place_of_worship', but only 3 tagged as 'internet_cafe'. Given that I can see more than 3 internet cafes from where I'm sitting, this indicates that the dataset is incomplete.\n",
    "\n",
    "One way I propose that this could be addressed is by cross-referencing with third-party datasets obtained from social media (Facebook, Twitter) or review-based applications (e.g. Yelp) where users are 'tagged' as being at a location, often with the type of establishment they are at (e.g. 'restaurant'). Therefore, the location can act as the foreign key to update a given node's 'amenity' field.\n",
    "\n",
    "This kind of implementation may have the following benefits/anticipated problems:\n",
    "\n",
    "**Benefits**  \n",
    "  * May be able to automate the process to handle the large amounts of data required\n",
    "  * Would allow for real-time/up-to-date cross-checking of amenity types. For example, near where I live there is a lot of business turnover, e.g. one day a location might be a 'restaurant', where one week later it's a 'hairdressers'. I imagine these are not being updated frequently in the osm data.\n",
    "\n",
    "**Anticipated Problems**  \n",
    "  * Conflicting entries. It's imagined that the lat./lon. location data may be set with some accepted margin of error to allow cross-compatibility between the datasets. This may lead to conflicting entries. However, its foreseeable that fine-tuning may minimize these occurances.\n",
    "  * Accessability of user data from third-parties. Privacy concerns/issues would need to be addressed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "The osm dataset for Melbourne is extremely large, which is to be expected given its relatively large population and hugh land area (i.e. low pop. density). There are many entries in this dataset with incomplete and/or missing attributes; however, given the size of the dataset the attributes that were inspected in this study (i.e. street names, postcodes, and amenities) were relatively clean. This allowed for the auditing/cleaning process to be conducted by directly writing  dictionaries/maps to replace, update, or remove entries. If the problematic entry sets were much larger then they would need to be cleaned more programtically. That being said, there is a huge wealth of information already available in this dataset thanks to the contributions of the 2490-ish users who have contributed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
